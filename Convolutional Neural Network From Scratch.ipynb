{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network From Scratch\n",
    "\n",
    "In this notebook we will implement a convolutional and a pooling layer from scratch, as well as the forward propagation step of a CNN, in order to better understand their inner working. \n",
    "\n",
    "For this matter, we'll rely on both `numpy` and `pandas`, two of the most pervasive, relevant and foundational Python libraries for data science and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "Let's start by importing the libraries we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now configure some default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Plan\n",
    "\n",
    "Our plan is to implement the following model:\n",
    "\n",
    "<img src=\"assets/model.png\" style=\"width:800px;height:300px;\">\n",
    "\n",
    "In particular, we'll implement functions to create two of the most important building blocks of CNNs: **Convolutional layers**, and **Pooling layers**. \n",
    "\n",
    "Given that for each forward functions there's a backward equivalent, we will store some parameters in a cache to avoid unnecessary re-computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs: Harder than They Look\n",
    "\n",
    "TensorFlow, Keras, fast.ai, PyTorch, Caffe, Deeplearning4j... These are some of the frameworks that make programming convolutional neural networks seem easy. However, CNNs remain one of the hardest concepts to understand in the field of deep learning. \n",
    "\n",
    "### Convolving\n",
    "\n",
    "This is the main operation of a convolutional layer. In a nutshell, it transforms an input volume into an output volume with different size.\n",
    "\n",
    "<img src=\"assets/conv_nn.png\" style=\"width:350px;height:200px;\">\n",
    "\n",
    "### Padding\n",
    "\n",
    "<img src=\"assets/PAD.png\" style=\"width:600px;height:400px;\">\n",
    "<caption><center> Zero-Padding<br> Image (3 channels, RGB) with a padding of 2. </center></caption>\n",
    "\n",
    "Padding consists of adding zeroes to the border of an image to allow convolution operations to happen near the edges of the picture.\n",
    "\n",
    "This has the benefit of helping us keep information that appears at the border of an image, which, without padding, would be otherwise lost.\n",
    "\n",
    "Also, we can convolve the volumes without necessarily shrinking the height and width of the volumes.\n",
    "\n",
    "Let's implement a padding function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    :param X: X is a tensor of dimensions (batch_size, height, width, number_of_channels)\n",
    "    :param pad: Amount of padding to be applied to the horizontal and vertical dimensions of a volume.\n",
    "    \n",
    "    :return Zero-padded X tensor with shape (batch_size, height + 2 * pad, width + 2 * pad, number_of_channels)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Here we apply 'constant' padding to the widht and height. The first and last [(0, 0)] tell np.pad we want to pad with zeroes\n",
    "    # each batch and each channel of the volume. The default contant value for padding is zero, that's why we don't specify it\n",
    "    # explicitly.\n",
    "    X_pad = np.pad(X, [(0, 0)] + [(pad, pad) for _ in range(len(X.shape[1:-1]))] + [(0, 0)], 'constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4, 3, 3, 2)\n",
      "X_pad shape: (4, 7, 7, 2)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "X = np.random.randn(4, 3, 3, 2)\n",
    "X_pad = zero_pad(X, 2)\n",
    "\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'X_pad shape: {X_pad.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show both X and X_pad as images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bcc039f9b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bcbe307be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].set_title('X')\n",
    "ax[0].imshow(X[0, :, :, 0])\n",
    "\n",
    "ax[1].set_title('X_pad')\n",
    "ax[1].imshow(X_pad[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `X_pad` has a thicker black area surrounding the original `X` image, which makes sense because 0 represents full black in a grayscale image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Step\n",
    "\n",
    "Let's now move to the main step: Convolving!\n",
    "\n",
    "Just as a quick reminder, see the image below to recall how a convolution operation works:\n",
    "\n",
    "<img src=\"assets/Convolution_schematic.gif\" style=\"width:500px;height:300px;\">\n",
    "<caption><center> Convolution operation<br> with a filter of 2x2 and a stride of 1 (stride = amount you move the window each time you slide) </center></caption>\n",
    "\n",
    "Here each value on the left corresponds to a single pixel value, and we are convolving them using a 3x3 filter. The operation, then, consists on multiplying the elements in the region of the image by the elements in the filter, in a element-wise fashion. Finally, we sum them all to produce a single entry in the resulting volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_step(previous_layer_slice, weights, bias):\n",
    "    s = np.multiply(previous_layer_slice, weights)\n",
    "    result = np.sum(s)\n",
    "    result += bias[0, 0, 0]\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.094205555853435\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "previous_layer_slice = np.random.randn(4, 4, 3)  \n",
    "weights = np.random.randn(4, 4, 3)  # This is the filter we will apply\n",
    "bias = np.random.rand(1, 1, 1)\n",
    "\n",
    "Z = convolution_step(previous_layer_slice, weights, bias)\n",
    "\n",
    "print(f'Z = {Z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw, the function we just implement applies a convolution operation over a single area/slace from the previous layer. Hence, if we actually want to produce a new volume, we must apply this function many tmes. In other words, we must implement a forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs - Forward Pass\n",
    "\n",
    "We will implement the following process:\n",
    "    \n",
    "<center>\n",
    "<video width=\"620\" height=\"440\" src=\"assets/conv_kiank.mp4\" type=\"video/mp4\" controls>\n",
    "</video>\n",
    "</center>\n",
    "\n",
    "We will apply a set of filters all over the input volume to produce the proper output.\n",
    "\n",
    "NOTE: We won't worry about efficiency here. We'll rather focus on simplicity. This is why we will implement an iterative solution instead of a vectorized one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_forward(previous_layer, filters, biases, hyper_parameters):\n",
    "    \n",
    "    # Extract previous layer dimensions\n",
    "    (batch_size, previous_height, previous_width, previous_channels) = previous_layer.shape\n",
    "    \n",
    "    \n",
    "    # Extract convolution filters dimensions\n",
    "    (filter_size, filter_size, previous_channels, number_of_filters) = filters.shape\n",
    "    \n",
    "    # Extract relevant hyper parameters.\n",
    "    stride = hyper_parameters['stride']\n",
    "    pad = hyper_parameters['pad']\n",
    "    \n",
    "    # Compute the dimensions of the output:\n",
    "    output_height = int((previous_height - filter_size + 2 * pad) / stride + 1)\n",
    "    output_width = int((previous_width - filter_size + 2 * pad) / stride + 1)\n",
    "    \n",
    "    # Initialize output volume with zeroes\n",
    "    output_volume = np.zeros((batch_size, output_height, output_width, number_of_filters))\n",
    "    \n",
    "    # Pad the previous layer\n",
    "    previous_layer_padded = zero_pad(previous_layer, pad)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        padded_training_example = previous_layer_padded[i, :, :, :]\n",
    "        \n",
    "        for h in range(0, output_height):\n",
    "            for w in range(0, output_width):\n",
    "                for c in range(number_of_filters):\n",
    "                \n",
    "                    # Find the corners of the current slice\n",
    "                    vertical_start = w\n",
    "                    vertical_end = w + filter_size\n",
    "                    horizontal_start = h\n",
    "                    horizontal_end = h + filter_size\n",
    "                    \n",
    "                    # Use the corners to define the (3D) slice of padded_training_example\n",
    "                    padded_slice = padded_training_example[vertical_start:vertical_end,\n",
    "                                                           horizontal_start:horizontal_end]\n",
    "                    \n",
    "                    # Apply convolution:\n",
    "                    weights = filters[:, :, :, c]\n",
    "                    bias = biases[:, :, :, c]\n",
    "                    \n",
    "                    output_volume[i, h, w, c] = convolution_step(padded_slice, weights, bias)\n",
    "                    \n",
    "    # Sanity check to check the output dimensions are correct\n",
    "    assert(output_volume.shape == (batch_size, output_height, output_width, number_of_filters))\n",
    "    \n",
    "    # Cache information\n",
    "    cache = (previous_layer, filters, biases, hyper_parameters)\n",
    "    \n",
    "    return output_volume, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output mean: -0.0078019720931586075\n",
      "output[3, 2, 1]: [ 0.49930938 -0.47299672  0.32697871  2.02563725  0.4256935   2.47682402\n",
      " -1.78597367  0.35094674]\n",
      "cache[0][1][2][3]: [-0.20075807  0.18656139  0.41005165]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "previous_layer = np.random.randn(10, 4, 4, 3)\n",
    "filters = np.random.randn(2, 2, 3, 8)\n",
    "biases = np.random.randn(1, 1, 1, 8)\n",
    "\n",
    "hyper_parameters = {\n",
    "    'pad': 2,\n",
    "    'stride': 2\n",
    "}\n",
    "\n",
    "output_volume, cache = convolution_forward(previous_layer, filters, biases, hyper_parameters)\n",
    "\n",
    "print(f'output mean: {np.mean(output_volume)}')\n",
    "print(f'output[3, 2, 1]: {output_volume[3, 2, 1]}')\n",
    "print(f'cache[0][1][2][3]: {cache[0][1][2][3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the resulting volume hasn't been activated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layers\n",
    "\n",
    "Pooling layers are a great way to both summarize the information in a volume and reduce its dimensionality.\n",
    "\n",
    "The method to do this follows a similar recipe than in the case of convolutions: We apply the operation over different slices of the input volume. However, we don't need filters. Instead, we always apply the same operaton (typically a `max` or `avg` operation).\n",
    "\n",
    "Although these layers don't need to be trained, they require some hyper parameters, such as the window size\n",
    "\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"assets/max_pool1.png\" style=\"width:500px;height:300px;\">\n",
    "<td>\n",
    "\n",
    "<td>\n",
    "<img src=\"assets/a_pool.png\" style=\"width:500px;height:300px;\">\n",
    "<td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement a function to apply either Max Pooling or Average Pooling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(previous_layer, hyper_parameters, mode='max'):\n",
    "    assert mode in {'max', 'average'}, 'Mode must be either max or average.'\n",
    "    \n",
    "    # Retrieve input shape\n",
    "    (batch_size, previous_height, previous_width, previous_channels) = previous_layer.shape\n",
    "    \n",
    "    # Retrieve relevant hyper parameters\n",
    "    window_size = hyper_parameters['window_size']\n",
    "    stride = hyper_parameters['stride']\n",
    "    \n",
    "    # Define output shape\n",
    "    output_height = int(1 + (previous_height - window_size) / stride)\n",
    "    output_width = int(1 + (previous_width - window_size) / stride)\n",
    "    output_channels = previous_channels\n",
    "    \n",
    "    # Initialize output\n",
    "    output_volume = np.zeros((batch_size, output_height, output_width, output_channels))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        for h in range(output_height):\n",
    "            for w in range(output_width):\n",
    "                for c in range(output_channels):\n",
    "                    \n",
    "                    # Find the corners of the current slice\n",
    "                    vertical_start = w\n",
    "                    vertical_end = w + window_size\n",
    "                    horizontal_start = h\n",
    "                    horizontal_end = h + window_size\n",
    "                    \n",
    "                    # Use the corners to define the current slice on the ith training example\n",
    "                    previous_slice = previous_layer[vertical_start:vertical_end,\n",
    "                                                    horizontal_start:horizontal_end,\n",
    "                                                    c]\n",
    "                    \n",
    "                    if mode == 'max':\n",
    "                        output_volume[i, h, w, c] = np.max(previous_slice)\n",
    "                    else:\n",
    "                        output_volume[i, h, w, c] = np.mean(previous_slice)\n",
    "                        \n",
    "    # Sanity check\n",
    "    assert output_volume.shape == (batch_size, output_height, output_width, output_channels)\n",
    "    \n",
    "    cache = (previous_layer, hyper_parameters)\n",
    "    \n",
    "    return output_volume, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: max\n",
      "Output: \n",
      "\t[[[[1.62434536 0.86540763 2.18557541]]]\n",
      "\n",
      "\n",
      " [[[1.62434536 0.86540763 2.18557541]]]]\n",
      "\n",
      "Mode: average\n",
      "Output: \n",
      "\t[[[[ 0.24481813 -0.47568152  0.3263877 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.24481813 -0.47568152  0.3263877 ]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "previous_layer = np.random.randn(2, 4, 4, 3)\n",
    "hyper_parameters = {\n",
    "    'stride': 2,\n",
    "    'window_size': 3\n",
    "}\n",
    "\n",
    "for mode in ['max', 'average']:\n",
    "    \n",
    "    output_volume, cache = pool_forward(previous_layer, hyper_parameters, mode)\n",
    "    print(f'Mode: {mode}')\n",
    "    print(f'Output: \\n\\t{output_volume}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are done! We implemented two of the most important building blocks of CNNs. Quite a handful of code, right? This is what deep learning frameworks like TensorFlow or Keras do under the hood."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
