{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Convolucionales Desde Cero\n",
    "\n",
    "En este notebook implementaremos una capa convolucional y una capa de agrupación desde cero, así como una función para aplicar las operaciones correspondientes, todo con el fin de entender mejor su funcionamiento.\n",
    "\n",
    "Con esta finalidad, nos apoyaremos tanto en `numpy` como en `matplotlib`, dos de las librerías de Python más relevantes, populares y fundacionales para data science y machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminares\n",
    "\n",
    "Empecemos importando las librerías que necesitaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora configuremos algunos parámetros por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestro Plan\n",
    "\n",
    "Nuestro plan es implementar el siguiente modelo:\n",
    "\n",
    "<img src=\"assets/model.png\" style=\"width:800px;height:300px;\">\n",
    "\n",
    "Particularmente, implementaremos funciones para crear dos de las piezas más importantes de una CNN: **Capas convolucionales**, y **capas de agrupamiento**.\n",
    "\n",
    "Dado que las redes neuronales propagan la información hacia adelante, y el error hacia atrás (para aprender), guardaremos algunos parámetros en un cache para evitar cálculos innecesarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs: Más Difíciles de lo que Parecen\n",
    "\n",
    "\n",
    "TensorFlow, Keras, fast.ai, PyTorch, Caffe, Deeplearning4j... Estos son algunos de los frameworks que hacen que programar una red neuronal convolucional parezca fácil. Sin embargo, las CNNs siguen siendo uno de los conceptos más difíciles de entender en el campo de deep learning.\n",
    "\n",
    "### Convolución\n",
    "\n",
    "Esta es la operación principal de una capa de convolución. En resumen, transforma un volumen de entrada en un volumen de salida con un tamaño diferente: \n",
    "\n",
    "<img src=\"assets/conv_nn.png\" style=\"width:350px;height:200px;\">\n",
    "\n",
    "### Padding\n",
    "\n",
    "<img src=\"assets/PAD.png\" style=\"width:600px;height:400px;\">\n",
    "<caption><center> Zero-Padding<br> Imagen (3 canales, RGB) con un padding de 2. </center></caption>\n",
    "\n",
    "Padding consiste en adicionar ceros a los bordes de una imagen (o volumen) para permitir que las operaciones de convolución se lleven a cabo cerca de los límites del mismo. \n",
    "\n",
    "Esto tiene el beneficio de ayudarnos a mantener la información que aparece en los bordes de la imagen, la cual, sin padding, se perdería.\n",
    "\n",
    "Así mismo, podemos aplicar convoluciones a volúmenes sin necesidad de reducir la altura o el peso de los volúmenes.\n",
    "\n",
    "Implementemos una función para aplicar padding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    :param X: X es un tensor de dimensiones (batch_size, height, width, number_of_channels).\n",
    "    :param pad: Cantidad de padding a ser aplicado horizontal y verticalmente al volumen.\n",
    "    \n",
    "    :return El tensor X padded con ceros y con dimensiones (batch_size, height + 2 * pad, width + 2 * pad, number_of_channels)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Aquí aplicamos padding 'constant' tanto al ancho como al alto. El primer y último [(0, 0)]  le indica a np.pad que queremos pad con ceros\n",
    "    # cada batch y cada canal del volumen. La constante por defecto es cero, razón por la cual no lo especificamos de manera explícita.\n",
    "    X_pad = np.pad(X, [(0, 0)] + [(pad, pad) for _ in range(len(X.shape[1:-1]))] + [(0, 0)], 'constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probémosla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4, 3, 3, 2)\n",
      "X_pad shape: (4, 7, 7, 2)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "X = np.random.randn(4, 3, 3, 2)\n",
    "X_pad = zero_pad(X, 2)\n",
    "\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'X_pad shape: {X_pad.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostremos X y X_pad como imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bcc039f9b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bcbe307be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].set_title('X')\n",
    "ax[0].imshow(X[0, :, :, 0])\n",
    "\n",
    "ax[1].set_title('X_pad')\n",
    "ax[1].imshow(X_pad[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que `X_pad` tiene un borde negro que rodea a la imagen original correspondiente a `X`, lo cual tiene sentido, puesto que 0 representa el color negro absoluto en escala de grises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso de Convolución\n",
    "\n",
    "Prosigamos con el paso principal: ¡Convolución!\n",
    "\n",
    "Sólo como un recordatorio rápido, mira la imagen de abajo para refrescar tu mente sobre cómo una operación de convolución funciona:\n",
    "\n",
    "<img src=\"assets/Convolution_schematic.gif\" style=\"width:500px;height:300px;\">\n",
    "<caption><center> Convolución con un filtro 2x2 y un stride de 1 (stride = cantidad de pixeles que desplazaremos la ventana cada vez que la deslicemos por la imagen) </center></caption>\n",
    "\n",
    "Aquí cada valor en la izquierda corresponde a un solo píxel, y estamos aplicando una convolución con un filtro 3x3. La operación, entonces, consiste en multiplicar la región de la imagen por los elementos en el filtro, posición por posición. Finalmente, sumamos todos los valores para producir una única entrada en el volumen resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_step(previous_layer_slice, weights, bias):\n",
    "    s = np.multiply(previous_layer_slice, weights)\n",
    "    result = np.sum(s)\n",
    "    result += bias[0, 0, 0]\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos la función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.094205555853435\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "previous_layer_slice = np.random.randn(4, 4, 3)  \n",
    "weights = np.random.randn(4, 4, 3)  # This is the filter we will apply\n",
    "bias = np.random.rand(1, 1, 1)\n",
    "\n",
    "Z = convolution_step(previous_layer_slice, weights, bias)\n",
    "\n",
    "print(f'Z = {Z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como observamos, la función que acabamos de implementar sólo aplica la convolución sobre un área o porción específica de la capa anterior. Por lo tanto, si realmente queremos producir un nuevo volumen, debemos aplicar esta función muchas veces. En otras palabras, debemos implementar una función de pase hacia adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs - Pase Hacia Adelante\n",
    "\n",
    "Implementaremos el siguiente proceso:\n",
    "    \n",
    "<center>\n",
    "<video width=\"620\" height=\"440\" src=\"assets/conv_kiank.mp4\" type=\"video/mp4\" controls>\n",
    "</video>\n",
    "</center>\n",
    "\n",
    "Aplicaremos un conjunto de filtros a todas las regiones de un volumen de entrada para producir la debida salida.\n",
    "\n",
    "NOTA: No nos preocuparemos por eficiencia. Más bien, nos enfocaremos en la simplicidad. Por esta razón, nuestra solución será iterativa, en vez de vectorizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_forward(previous_layer, filters, biases, hyper_parameters):\n",
    "    \n",
    "    # Extrae las dimensiones de la capa anterior\n",
    "    (batch_size, previous_height, previous_width, previous_channels) = previous_layer.shape\n",
    "    \n",
    "    \n",
    "    # Extrae las dimensiones de los filtros de convolución\n",
    "    (filter_size, filter_size, previous_channels, number_of_filters) = filters.shape\n",
    "    \n",
    "    # Extrae los hiperparámetros relevantes.\n",
    "    stride = hyper_parameters['stride']\n",
    "    pad = hyper_parameters['pad']\n",
    "    \n",
    "    # Calcula las dimensiones del volumen de salida\n",
    "    output_height = int((previous_height - filter_size + 2 * pad) / stride + 1)\n",
    "    output_width = int((previous_width - filter_size + 2 * pad) / stride + 1)\n",
    "    \n",
    "    # Inicializa el volumen de salida con ceros.\n",
    "    output_volume = np.zeros((batch_size, output_height, output_width, number_of_filters))\n",
    "    \n",
    "    # Aplica padding a la capa anterior (entrada)\n",
    "    previous_layer_padded = zero_pad(previous_layer, pad)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        padded_training_example = previous_layer_padded[i, :, :, :]\n",
    "        \n",
    "        for h in range(output_height):\n",
    "            for w in range(output_width):\n",
    "                for c in range(number_of_filters):\n",
    "                \n",
    "                    # Encuetra los vértices de la región de interés para \n",
    "                    # el ejemplo de entrenamiento actual\n",
    "                    vertical_start = w\n",
    "                    vertical_end = w + filter_size\n",
    "                    horizontal_start = h\n",
    "                    horizontal_end = h + filter_size\n",
    "                    \n",
    "                    # Usa estos vértices para definir la porción (3D) del padded_training_example\n",
    "                    padded_slice = padded_training_example[vertical_start:vertical_end,\n",
    "                                                           horizontal_start:horizontal_end]\n",
    "                    \n",
    "                    # Aplica la convolución\n",
    "                    weights = filters[:, :, :, c]\n",
    "                    bias = biases[:, :, :, c]\n",
    "                    \n",
    "                    output_volume[i, h, w, c] = convolution_step(padded_slice, weights, bias)\n",
    "                    \n",
    "    # Verificamos que las dimensiones son las correctas.\n",
    "    assert(output_volume.shape == (batch_size, output_height, output_width, number_of_filters))\n",
    "    \n",
    "    # Guardamos la información en cache.\n",
    "    cache = (previous_layer, filters, biases, hyper_parameters)\n",
    "    \n",
    "    return output_volume, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output mean: -0.0078019720931586075\n",
      "output[3, 2, 1]: [ 0.49930938 -0.47299672  0.32697871  2.02563725  0.4256935   2.47682402\n",
      " -1.78597367  0.35094674]\n",
      "cache[0][1][2][3]: [-0.20075807  0.18656139  0.41005165]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "previous_layer = np.random.randn(10, 4, 4, 3)\n",
    "filters = np.random.randn(2, 2, 3, 8)\n",
    "biases = np.random.randn(1, 1, 1, 8)\n",
    "\n",
    "hyper_parameters = {\n",
    "    'pad': 2,\n",
    "    'stride': 2\n",
    "}\n",
    "\n",
    "output_volume, cache = convolution_forward(previous_layer, filters, biases, hyper_parameters)\n",
    "\n",
    "print(f'output mean: {np.mean(output_volume)}')\n",
    "print(f'output[3, 2, 1]: {output_volume[3, 2, 1]}')\n",
    "print(f'cache[0][1][2][3]: {cache[0][1][2][3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten en cuenta que el volumen resultante no ha sido activado (es decir, no usamos una función de activación como ReLu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capas de Agrupación\n",
    "\n",
    "Las capas de agrupación son una gran herramienta tanto para resumir la información de un volumen, así como para reducir su dimensionalidad.\n",
    "\n",
    "El método para hacer esto sigue una receta similar a la de las convoluciones: Aplicaremos la operación específica sobre diferentes regiones del volumen de entrada. Sin embargo, no necesitamos filtros como tal. En cambio, siempre aplicaremos la misma operación (típicamente `max` o `avg`).\n",
    "\n",
    "Aunque éstas capas no necesitan entrenamiento, sí requieren algunos hiperparámetros, tales como el tamaño o dimensiones de la ventana de aplicación.\n",
    "\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"assets/max_pool1.png\" style=\"width:500px;height:300px;\">\n",
    "<td>\n",
    "\n",
    "<td>\n",
    "<img src=\"assets/a_pool.png\" style=\"width:500px;height:300px;\">\n",
    "<td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementemos una función para aplicar Max Pooling o Average Pooling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(previous_layer, hyper_parameters, mode='max'):\n",
    "    assert mode in {'max', 'average'}, 'Mode must be either max or average.'\n",
    "    \n",
    "    # Obtiene las dimensiones del volumen de entrada.\n",
    "    (batch_size, previous_height, previous_width, previous_channels) = previous_layer.shape\n",
    "    \n",
    "    # Obtiene los hiperparámetros de interés.\n",
    "    window_size = hyper_parameters['window_size']\n",
    "    stride = hyper_parameters['stride']\n",
    "    \n",
    "    # Define las dimensiones del volumen de salida.\n",
    "    output_height = int(1 + (previous_height - window_size) / stride)\n",
    "    output_width = int(1 + (previous_width - window_size) / stride)\n",
    "    output_channels = previous_channels\n",
    "    \n",
    "    # Inicializa el volumen de salida.\n",
    "    output_volume = np.zeros((batch_size, output_height, output_width, output_channels))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        for h in range(output_height):\n",
    "            for w in range(output_width):\n",
    "                for c in range(output_channels):\n",
    "                    \n",
    "                    # Encuentra los vértices de la porción actual.\n",
    "                    vertical_start = w\n",
    "                    vertical_end = w + window_size\n",
    "                    horizontal_start = h\n",
    "                    horizontal_end = h + window_size\n",
    "                    \n",
    "                    # Usa los vértices para definir la porción actual del i-ésimo ejemplo de entrenamiento.\n",
    "                    previous_slice = previous_layer[vertical_start:vertical_end,\n",
    "                                                    horizontal_start:horizontal_end,\n",
    "                                                    c]\n",
    "                    \n",
    "                    if mode == 'max':\n",
    "                        output_volume[i, h, w, c] = np.max(previous_slice)\n",
    "                    else:\n",
    "                        output_volume[i, h, w, c] = np.mean(previous_slice)\n",
    "                        \n",
    "    # Sanity check\n",
    "    assert output_volume.shape == (batch_size, output_height, output_width, output_channels)\n",
    "    \n",
    "    cache = (previous_layer, hyper_parameters)\n",
    "    \n",
    "    return output_volume, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrida de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: max\n",
      "Output: \n",
      "\t[[[[1.62434536 0.86540763 2.18557541]]]\n",
      "\n",
      "\n",
      " [[[1.62434536 0.86540763 2.18557541]]]]\n",
      "\n",
      "Mode: average\n",
      "Output: \n",
      "\t[[[[ 0.24481813 -0.47568152  0.3263877 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.24481813 -0.47568152  0.3263877 ]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "previous_layer = np.random.randn(2, 4, 4, 3)\n",
    "hyper_parameters = {\n",
    "    'stride': 2,\n",
    "    'window_size': 3\n",
    "}\n",
    "\n",
    "for mode in ['max', 'average']:\n",
    "    \n",
    "    output_volume, cache = pool_forward(previous_layer, hyper_parameters, mode)\n",
    "    print(f'Mode: {mode}')\n",
    "    print(f'Output: \\n\\t{output_volume}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Estamos listos! Acabamos de implementar dos de los elementos más importantes para construir CNNs. Vaya montón de código, ¿no? Esto es lo que frameworks de deep learning como TensorFlow o Keras hacen por debajo, lo que facilita nuestras vidas inmensamente. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
